A web crawler is a program mainly used to create a copy of all the visited pages for later processing by a search engine, using multithreading to improve speed of downloading and parsing.

Future works :
1- More threading management.
2- Create a visualizer for crawled data.
